# ğŸ§© AI2Code â€” AI-Powered Figma â†’ React/Tailwind Generator

> **Design-to-code, reimagined for AI-native teams**

AI2Code converts Figma designs into production-ready **React + TypeScript + TailwindCSS** components. It parses Figma JSON, normalizes layout structure, and uses LLMs to generate clean, accessible UI code.

[![Live Demo](https://img.shields.io/badge/demo-live-brightgreen)](https://your-vercel-url.vercel.app)
[![GitHub](https://img.shields.io/badge/github-AI2Code-blue)](https://github.com/nagendracse24/AI2Code)

---

## âœ¨ Features

- **Figma-native parsing** â€” Pull real nodes, constraints, and typography straight from your file
- **LLM-ready schema** â€” Normalize design JSON into a compact prompt format engineered for codegen
- **Production output** â€” Generate React + Tailwind blocks with copy + download in one click
- **Live preview** â€” See generated components rendered in real-time
- **Observable pipeline** â€” Full transparency into inputs, normalization, LLM prompts, and output
- **Demo & live modes** â€” Works without credentials; plug in tokens for real Figma + OpenAI integration

---

## ğŸ—ï¸ Project Structure

```
AI2code/
â”œâ”€â”€ backend/              # Node.js + Express + TypeScript API
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts      # Express server entry point
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ figmaClient.ts    # Figma API integration
â”‚   â”‚       â””â”€â”€ llmGenerator.ts   # OpenAI LLM integration
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ frontend/             # React + Vite + TypeScript UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx       # Main application component
â”‚   â”‚   â”œâ”€â”€ main.tsx      # React entry point
â”‚   â”‚   â””â”€â”€ index.css     # TailwindCSS imports
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ vercel.json           # Vercel deployment config
â”œâ”€â”€ DEPLOYMENT.md         # Detailed deployment guide
â””â”€â”€ README.md             # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- (Optional) Figma Personal Access Token for live mode
- (Optional) OpenAI API key for LLM-powered generation

### Local Development

1. **Clone the repository**
   ```bash
   git clone https://github.com/nagendracse24/AI2Code.git
   cd AI2Code
   ```

2. **Backend setup**
   ```bash
   cd backend
   npm install
   cp env.example .env
   # Edit .env and add your keys (optional for demo mode)
   npm run dev
   ```
   Backend runs on `http://localhost:3001`

3. **Frontend setup** (in a new terminal)
   ```bash
   cd frontend
   npm install
   npm run dev
   ```
   Frontend runs on `http://localhost:3000`

4. **Visit** `http://localhost:3000` and submit a Figma URL or use demo mode

---

## ğŸŒ Deployment

Deploy to production using Vercel (frontend) + Render (backend).

**ğŸ‘‰ See [DEPLOYMENT.md](./DEPLOYMENT.md) for the complete step-by-step guide.**

Quick overview:
1. Deploy backend to Render (free tier)
2. Deploy frontend to Vercel (auto-deploy on push)
3. Set environment variables on each platform
4. Update CORS and API proxy URLs

---

## ğŸ”§ Tech Stack

### Backend
- **Runtime**: Node.js + TypeScript
- **Framework**: Express.js
- **APIs**: Figma REST API, OpenAI Chat Completions
- **Tools**: dotenv, cors, node-fetch

### Frontend
- **Framework**: React 18 + TypeScript
- **Build tool**: Vite
- **Styling**: TailwindCSS
- **Code preview**: react-live
- **Deployment**: Vercel

---

## ğŸ“‹ Environment Variables

### Backend (`backend/.env`)

```bash
PORT=3001
FRONTEND_URL=              # Your Vercel URL (for CORS in production)
FIGMA_PERSONAL_ACCESS_TOKEN=   # Optional: for live Figma mode
OPENAI_API_KEY=            # Optional: for LLM-powered generation
```

### Frontend

No environment variables required (proxies to backend via Vite/Vercel config).

---

## ğŸ¯ Usage

1. **Demo mode** (no credentials needed)
   - Submit any Figma URL or leave fields empty
   - System returns a baseline component + mock AI draft

2. **Live Figma mode**
   - Add `FIGMA_PERSONAL_ACCESS_TOKEN` to backend `.env`
   - Enter a valid `fileKey` + `nodeId` from your Figma file
   - Backend fetches real node data and normalizes it

3. **AI-powered mode**
   - Add `OPENAI_API_KEY` to backend `.env`
   - System sends normalized schema to OpenAI
   - Returns LLM-generated React component

4. **Live preview**
   - Click the "Live preview" tab to see the component rendered in real-time

---

## ğŸ¤ Contributing

This is a portfolio project, but suggestions and feedback are welcome! Open an issue or PR if you have ideas for improvements.

---

## ğŸ“„ License

MIT License - see [LICENSE](./LICENSE) for details

---

## ğŸ‘¤ Author

**Nagendra Singh**  
Software Engineer | AI + Full-Stack Developer

- GitHub: [@nagendracse24](https://github.com/nagendracse24)
- Email: nagendracse24@gmail.com

---

## ğŸ™ Acknowledgments

- Figma API for design data access
- OpenAI for LLM-powered code generation
- React, Vite, TailwindCSS communities

---

Built with â¤ï¸ by Nagendra Singh
